{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Karpathy Makemore using MLP\n",
    "\n",
    "[Video](https://www.youtube.com/watch?v=TCH_1BHY58I&t=10s)\n",
    "\n",
    "Paper [A neural probabilistic language model](https://jmlr.org/papers/volume3/bengio03a/bengio03a.pdf). Bengio et al, 2003.\n",
    "\n",
    "The paper uses three previous words to predict a fourth word. It uses a vocabulary of 17k words, implemented in a 30-dimensional space.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots\n",
    "using Flux\n",
    "using Flux: softmax, crossentropy\n",
    "using Statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Vector{SubString{String}}:\n",
       " \"emma\"\n",
       " \"olivia\"\n",
       " \"ava\"\n",
       " \"isabella\"\n",
       " \"sophia\"\n",
       " \"charlotte\"\n",
       " \"mia\"\n",
       " \"amelia\"\n",
       " \"harper\"\n",
       " \"evelyn\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read names.txt into words array:\n",
    "f = open(\"names.txt\",\"r\")\n",
    "    s = read(f,String)\n",
    "close(f)\n",
    "words = split(s,\"\\r\\n\")\n",
    "words[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Int64, Char} with 27 entries:\n",
       "  5  => 'd'\n",
       "  16 => 'o'\n",
       "  20 => 's'\n",
       "  12 => 'k'\n",
       "  24 => 'w'\n",
       "  8  => 'g'\n",
       "  17 => 'p'\n",
       "  1  => '.'\n",
       "  19 => 'r'\n",
       "  22 => 'u'\n",
       "  23 => 'v'\n",
       "  6  => 'e'\n",
       "  11 => 'j'\n",
       "  9  => 'h'\n",
       "  14 => 'm'\n",
       "  3  => 'b'\n",
       "  7  => 'f'\n",
       "  25 => 'x'\n",
       "  4  => 'c'\n",
       "  ⋮  => ⋮"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create character embeddings.\n",
    "chars = \".abcdefghijklmnopqrstuvwxyz\"\n",
    "stoi = Dict( s => i for (i,s) in enumerate(chars))\n",
    "itos = Dict( i => s for (i,s) in enumerate(chars))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to follow what Karpathy does pretty closely. The section of the FluxML docs called [Building Simple Models](https://fluxml.ai/Flux.jl/stable/models/basics/#Building-Simple-Models) gives a good foundation for doing this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emma\n",
      "... ---> e\n",
      "..e ---> m\n",
      ".em ---> m\n",
      "emm ---> a\n",
      "mma ---> .\n",
      "olivia\n",
      "... ---> o\n",
      "..o ---> l\n",
      ".ol ---> i\n",
      "oli ---> v\n",
      "liv ---> i\n",
      "ivi ---> a\n",
      "via ---> .\n",
      "ava\n",
      "... ---> a\n",
      "..a ---> v\n",
      ".av ---> a\n",
      "ava ---> .\n",
      "isabella\n",
      "... ---> i\n",
      "..i ---> s\n",
      ".is ---> a\n",
      "isa ---> b\n",
      "sab ---> e\n",
      "abe ---> l\n",
      "bel ---> l\n",
      "ell ---> a\n",
      "lla ---> .\n",
      "sophia\n",
      "... ---> s\n",
      "..s ---> o\n",
      ".so ---> p\n",
      "sop ---> h\n",
      "oph ---> i\n",
      "phi ---> a\n",
      "hia ---> .\n"
     ]
    }
   ],
   "source": [
    "# Compile dataset for neural net:\n",
    "block_size = 3 # context length: how many chars to we use to predict next one?\n",
    "X0,Y = [],[]\n",
    "\n",
    "for w in words[1:5]\n",
    "    println(w)\n",
    "    context = ones(Int64,block_size)\n",
    "    for ch in string(w,\".\")\n",
    "        ix = stoi[ch]\n",
    "        push!(X0,context)\n",
    "        push!(Y,ix)\n",
    "        println(join(itos[i] for i in context),\" ---> \", itos[ix])\n",
    "        context = vcat(context[2:end],[ix])\n",
    "    end\n",
    "end\n",
    "\n",
    "# Repack X0 matrix\n",
    "nrows = length(X0)\n",
    "ncols = length(X0[1])\n",
    "X = zeros(Int64,nrows,ncols)\n",
    "for i in 1:nrows\n",
    "    X[i,:] = X0[i]\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Params([[1.8197007323445145 -0.8079439744014011; -1.7314098032732224 1.5563094980896302; … ; -0.08004252300479721 1.1899944593731064; 1.6569070441219902 1.3412677139150082], [-1.111047975208029 -0.06766944205595722 … 0.8463383387475465 1.1668584803968984; 0.07156469645212657 0.24862871936268277 … 0.5192622439763575 -2.71520604614454; … ; -0.2648886239908921 -0.26405886798078904 … 1.3072190132648311 1.739390978433306; 0.8365958465465413 -0.6659748182857015 … 0.29011320966727994 0.3968219524806097], [-2.242851973006484, -0.4156323600482659, -2.3007000471448458, -0.47256799301848434, 1.5664737480070696, 0.1952613208515643, 1.4820197686500372, -1.228291313957615, -1.1911617148138494, 0.901103884799183  …  0.18100283616677387, -0.6972702267662075, -1.4659665442573204, -0.6239243989451176, 0.2865205731780754, -0.9061374037810423, 0.6438560664825393, -0.9299798439948186, 1.1332483983134027, 0.39696977573496955], [-0.3470719647057009 -2.1473733458645654 … 1.8771317160188554 0.2461452378591509; 0.2312813168335692 -0.5139609141200712 … -0.2726381914529615 0.9055612838216022; … ; -2.5634736805520273 -0.1145366038854757 … 0.9117333274583873 1.8757445305575395; 0.6827745836068165 -0.9270791214933103 … 0.5127115327450351 -0.6048443536336598], [-1.5803512258968375, 1.6876348514093442, 0.5967450263295313, -0.5258672142568629, -0.5823313939228634, -0.9112139172339204, -0.41459497600076123, -1.8307778622274966, 0.6565065318342401, -0.6969618241302876  …  0.741131702014176, -0.2835484124764935, 0.12605826305666826, 1.9966928084184306, -0.7503523928804934, -0.8041448629855908, -0.13206705889223724, -0.8997435302663102, -0.8680456268694683, -0.891857929122744]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "C = randn(27,2)  # Build embedding lookup table C.\n",
    "W1 = randn(6,100)\n",
    "b1 = randn(100)'\n",
    "W2 = randn(100,27)\n",
    "b2 = randn(27)';\n",
    "params = Flux.params(C,W1,b1,W2,b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mloss (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Forward pass\n",
    "function predict(X)\n",
    "    Xemb = hcat(C[X[:,1],:],C[X[:,2],:],C[X[:,3],:]) # Build the embedded input matrix:\n",
    "    h = tanh.(Xemb*W1 .+ b1)\n",
    "    return h*W2 .+ b2\n",
    "end\n",
    "\n",
    "function mloss(X,Y)\n",
    "    logits = predict(X)\n",
    "    # This should be equivalent to softmax, but Flux's softmax doesn't give the same result:\n",
    "    counts = exp.(logits)\n",
    "    prob = zeros(Float64,size(counts))\n",
    "    for i in 1:size(prob)[1]\n",
    "        prob[i,:] = counts[i,:]/sum(counts[i,:])\n",
    "    end\n",
    "    #prob[1:32,Y] # This is what AK does in Python\n",
    "\n",
    "    # This should be the same as crossentropy, but Flux's crossentropy doesn't give the same result\n",
    "    results = [prob[i,Y[i]] for i in 1:32]  # Here's what does that operation in Julia\n",
    "    return -mean(log.(results))\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "MethodError",
     "evalue": "MethodError: no method matching (::var\"#27#28\")()\n\nClosest candidates are:\n  (::var\"#27#28\")(!Matched::Any, !Matched::Any)\n   @ Main c:\\Users\\RichardMullerGovernm\\OneDrive\\Programming\\Karpathy\\Karpathy\\karpathy-makemore-mlp.ipynb:1\n",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching (::var\"#27#28\")()\n",
      "\n",
      "Closest candidates are:\n",
      "  (::var\"#27#28\")(!Matched::Any, !Matched::Any)\n",
      "   @ Main c:\\Users\\RichardMullerGovernm\\OneDrive\\Programming\\Karpathy\\Karpathy\\karpathy-makemore-mlp.ipynb:1\n",
      "\n",
      "\n",
      "Stacktrace:\n",
      " [1] macro expansion\n",
      "   @ C:\\Users\\RichardMullerGovernm\\.julia\\packages\\Zygote\\nsBv0\\src\\compiler\\interface2.jl:0 [inlined]\n",
      " [2] _pullback(::Zygote.Context{true}, ::var\"#27#28\")\n",
      "   @ Zygote C:\\Users\\RichardMullerGovernm\\.julia\\packages\\Zygote\\nsBv0\\src\\compiler\\interface2.jl:87\n",
      " [3] pullback(f::Function, ps::Zygote.Params{Zygote.Buffer{Any, Vector{Any}}})\n",
      "   @ Zygote C:\\Users\\RichardMullerGovernm\\.julia\\packages\\Zygote\\nsBv0\\src\\compiler\\interface.jl:465\n",
      " [4] gradient(f::Function, args::Zygote.Params{Zygote.Buffer{Any, Vector{Any}}})\n",
      "   @ Zygote C:\\Users\\RichardMullerGovernm\\.julia\\packages\\Zygote\\nsBv0\\src\\compiler\\interface.jl:147\n",
      " [5] top-level scope\n",
      "   @ c:\\Users\\RichardMullerGovernm\\OneDrive\\Programming\\Karpathy\\Karpathy\\karpathy-makemore-mlp.ipynb:1"
     ]
    }
   ],
   "source": [
    "gs = gradient((X,Y) -> mloss(X,Y),Flux.params(C,W1,b1,W2,b2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.2",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
