{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux, StatsBase, Random\n",
    "using Flux: onehotbatch, onecold, logitcrossentropy, throttle, params\n",
    "using Flux.Data: DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033-element Vector{SubString{String}}:\n",
       " \"gift\"\n",
       " \"shabaz\"\n",
       " \"neilson\"\n",
       " \"tyriq\"\n",
       " \"jatavion\"\n",
       " \"azlan\"\n",
       " \"aubreerose\"\n",
       " \"binyamin\"\n",
       " \"waleed\"\n",
       " \"kahron\"\n",
       " ⋮\n",
       " \"lanston\"\n",
       " \"eniyah\"\n",
       " \"trygg\"\n",
       " \"katiya\"\n",
       " \"psalm\"\n",
       " \"oluwanifemi\"\n",
       " \"kumar\"\n",
       " \"gargi\"\n",
       " \"alyson\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "words = split(read(\"names.txt\",String),\"\\n\")\n",
    "words[1:10]\n",
    "shuffle!(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Int64, Char} with 27 entries:\n",
       "  5  => 'd'\n",
       "  16 => 'o'\n",
       "  20 => 's'\n",
       "  12 => 'k'\n",
       "  24 => 'w'\n",
       "  8  => 'g'\n",
       "  17 => 'p'\n",
       "  1  => '.'\n",
       "  19 => 'r'\n",
       "  22 => 'u'\n",
       "  23 => 'v'\n",
       "  6  => 'e'\n",
       "  11 => 'j'\n",
       "  9  => 'h'\n",
       "  14 => 'm'\n",
       "  3  => 'b'\n",
       "  7  => 'f'\n",
       "  25 => 'x'\n",
       "  4  => 'c'\n",
       "  ⋮  => ⋮"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create character embeddings. We're going to do this a little\n",
    "# differently, so that we can have the same embeddings AK uses.\n",
    "# I.e. the index of \".\" is 0\n",
    "chars = \".abcdefghijklmnopqrstuvwxyz\"\n",
    "stoi = Dict( s => i for (i,s) in enumerate(chars))\n",
    "itos = Dict( i => s for (i,s) in enumerate(chars))\n",
    "vocab_size = length(chars)\n",
    "itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((228146, 3), (228146,))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compile dataset for neural net:\n",
    "block_size = 3 # context length: how many chars to we use to predict next one?\n",
    "Xi,Y = [],[]\n",
    "\n",
    "for w in words\n",
    "    #println(w)\n",
    "    context = ones(Int64,block_size)\n",
    "    for ch in string(w,\".\")\n",
    "        ix = stoi[ch]\n",
    "        push!(Xi,context)\n",
    "        push!(Y,ix)\n",
    "        #println(join(itos[i] for i in context),\" ---> \", itos[ix])\n",
    "        context = vcat(context[2:end],[ix])\n",
    "    end\n",
    "end\n",
    "\n",
    "\n",
    "# Make into a multidimensional array\n",
    "nrows,ncols = length(Xi),length(Xi[1])\n",
    "X = zeros(Int64,nrows,ncols)\n",
    "for i in 1:nrows\n",
    "    X[i,:] = Xi[i]\n",
    "end\n",
    "\n",
    "ntrial = nrows\n",
    "\n",
    "size(X), size(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28829:32033"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# break the code into training, development, and testing sets\n",
    "nw = length(words)\n",
    "n1 = 8*nw÷10\n",
    "n2 = 9*nw÷10\n",
    "\n",
    "# Ranges are\n",
    "train = 1:n1\n",
    "dev = n1:n2\n",
    "test = n2:nw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "801-element DataLoader(::Tuple{Base.ReshapedArray{Bool, 2, OneHotArrays.OneHotArray{UInt32, 2, 3, Matrix{UInt32}}, Tuple{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64}, Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64}}}, OneHotArrays.OneHotMatrix{UInt32, Vector{UInt32}}}, batchsize=32)\n",
       "  with first element:\n",
       "  (81×32 Matrix{Bool}, 27×32 OneHotMatrix(::Vector{UInt32}) with eltype Bool,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Xoh = reshape(onehotbatch(X[train,:]',1:27),81,:)\n",
    "Yoh = onehotbatch(Y[train],1:27)\n",
    "\n",
    "# If you don't want to use a smaller batchsize, you can just use an array\n",
    "# for data:\n",
    "#data = [(Xoh,Yoh)]\n",
    "data = DataLoader((Xoh,Yoh), batchsize=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(\n",
       "  Dense(81 => 200, tanh),               \u001b[90m# 16_400 parameters\u001b[39m\n",
       "  Dense(200 => 27),                     \u001b[90m# 5_427 parameters\u001b[39m\n",
       "  NNlib.softmax,\n",
       ") \u001b[90m                  # Total: 4 arrays, \u001b[39m21_827 parameters, 85.512 KiB."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss(X,Y) = logitcrossentropy(model(X),Y)\n",
    "\n",
    "n_hidden = 200\n",
    "\n",
    "model = Chain(\n",
    "    Dense(block_size*vocab_size => n_hidden, tanh),\n",
    "    Dense(n_hidden => vocab_size),\n",
    "    softmax\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam(0.0003, (0.9, 0.999), 1.0e-8, IdDict{Any, Any}())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rate = 3e-4\n",
    "opt = Adam(rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 3.296538\n",
      "Loss 3.110311\n",
      "Loss 3.099118\n",
      "Loss 3.095139\n",
      "Loss 3.0885603\n",
      "Loss 3.0850244\n",
      "Loss 3.0832145\n",
      "Loss 3.0818505\n",
      "Loss 3.0772765\n",
      "Loss 3.0738816\n",
      "Loss 3.0720341\n",
      "Loss 3.0708532\n",
      "Loss 3.0697448\n",
      "Loss 3.0686243\n",
      "Loss 3.0676422\n",
      "Loss 3.06674\n",
      "Loss 3.0656765\n",
      "Loss 3.064275\n",
      "Loss 3.0626867\n",
      "Loss 3.0617065\n",
      "Loss 3.0609453\n",
      "Loss 3.060307\n",
      "Loss 3.059738\n",
      "Loss 3.0591815\n",
      "Loss 3.0586722\n",
      "Loss 3.0582416\n",
      "Loss 3.057862\n",
      "Loss 3.0575073\n",
      "Loss 3.0571716\n",
      "Loss 3.056859\n",
      "Loss 3.0565648\n",
      "Loss 3.056282\n",
      "Loss 3.055629\n",
      "Loss 3.0553412\n",
      "Loss 3.055093\n",
      "Loss 3.054848\n",
      "Loss 3.054604\n",
      "Loss 3.0543575\n",
      "Loss 3.0541077\n",
      "Loss 3.0538561\n",
      "Loss 3.0536053\n",
      "Loss 3.0533478\n",
      "Loss 3.0530944\n",
      "Loss 3.0528677\n",
      "Loss 3.052651\n",
      "Loss 3.0524318\n",
      "Loss 3.0522127\n",
      "Loss 3.0520155\n",
      "Loss 3.0518444\n",
      "Loss 3.051687\n",
      "Loss 3.0515375\n",
      "Loss 3.051393\n",
      "Loss 3.0512514\n",
      "Loss 3.0511117\n",
      "Loss 3.050975\n",
      "Loss 3.0508437\n",
      "Loss 3.050718\n",
      "Loss 3.0505974\n",
      "Loss 3.0504816\n",
      "Loss 3.0503697\n",
      "Loss 3.0502613\n",
      "Loss 3.0501559\n",
      "Loss 3.0500536\n",
      "Loss 3.0499535\n",
      "Loss 3.0498533\n",
      "Loss 3.0497463\n",
      "Loss 3.0496042\n",
      "Loss 3.0494883\n",
      "Loss 3.0493972\n",
      "Loss 3.049309\n",
      "Loss 3.049221\n",
      "Loss 3.049134\n",
      "Loss 3.049051\n",
      "Loss 3.0489721\n",
      "Loss 3.0488973\n",
      "Loss 3.0488255\n",
      "Loss 3.0487554\n",
      "Loss 3.0486834\n",
      "Loss 3.0486019\n",
      "Loss 3.0485063\n",
      "Loss 3.0484226\n",
      "Loss 3.0483456\n",
      "Loss 3.0482743\n",
      "Loss 3.0482063\n",
      "Loss 3.0481377\n",
      "Loss 3.0480652\n",
      "Loss 3.0479915\n",
      "Loss 3.0479243\n",
      "Loss 3.047863\n",
      "Loss 3.047803\n",
      "Loss 3.0477448\n",
      "Loss 3.0476897\n",
      "Loss 3.0476353\n",
      "Loss 3.0475774\n",
      "Loss 3.0473652\n",
      "Loss 3.047258\n",
      "Loss 3.047194\n",
      "Loss 3.0471306\n",
      "Loss 3.0470688\n",
      "Loss 3.0470088\n",
      "Loss 3.0469482\n",
      "Loss 3.046888\n",
      "Loss 3.046833\n",
      "Loss 3.04678\n",
      "Loss 3.0467234\n",
      "Loss 3.0466182\n",
      "Loss 3.0465133\n",
      "Loss 3.046446\n",
      "Loss 3.0463934\n",
      "Loss 3.0463457\n",
      "Loss 3.0462985\n",
      "Loss 3.0462513\n",
      "Loss 3.0462031\n",
      "Loss 3.046154\n",
      "Loss 3.046103\n",
      "Loss 3.046049\n",
      "Loss 3.0459921\n",
      "Loss 3.0459323\n",
      "Loss 3.045871\n",
      "Loss 3.045819\n",
      "Loss 3.0457737\n",
      "Loss 3.0457318\n",
      "Loss 3.0456934\n",
      "Loss 3.0456574\n",
      "Loss 3.0456233\n",
      "Loss 3.0455916\n",
      "Loss 3.0455587\n",
      "Loss 3.0455241\n",
      "Loss 3.0454884\n",
      "Loss 3.0454507\n",
      "Loss 3.0454135\n",
      "Loss 3.0453782\n",
      "Loss 3.045346\n",
      "Loss 3.045316\n",
      "Loss 3.0452855\n",
      "Loss 3.0452547\n",
      "Loss 3.0452218\n",
      "Loss 3.0451827\n",
      "Loss 3.0451345\n",
      "Loss 3.0450866\n",
      "Loss 3.045044\n",
      "Loss 3.0450022\n",
      "Loss 3.0449636\n",
      "Loss 3.04493\n",
      "Loss 3.0448983\n",
      "Loss 3.0448685\n",
      "Loss 3.0448384\n",
      "Loss 3.0448093\n",
      "Loss 3.0447793\n",
      "Loss 3.044748\n",
      "Loss 3.0447154\n",
      "Loss 3.044681\n",
      "Loss 3.0446427\n",
      "Loss 3.0445988\n",
      "Loss 3.044565\n",
      "Loss 3.0445418\n",
      "Loss 3.0445185\n",
      "Loss 3.0444922\n",
      "Loss 3.0444622\n",
      "Loss 3.0444305\n",
      "Loss 3.0443983\n",
      "Loss 3.0443664\n",
      "Loss 3.0443332\n",
      "Loss 3.0442996\n",
      "Loss 3.0442672\n",
      "Loss 3.0442374\n",
      "Loss 3.0442092\n",
      "Loss 3.0441825\n",
      "Loss 3.0441544\n",
      "Loss 3.044127\n",
      "Loss 3.0441008\n",
      "Loss 3.044077\n",
      "Loss 3.044054\n",
      "Loss 3.044033\n",
      "Loss 3.0440154\n",
      "Loss 3.044\n",
      "Loss 3.04398\n",
      "Loss 3.0439262\n",
      "Loss 3.0436733\n",
      "Loss 3.0436153\n",
      "Loss 3.043591\n",
      "Loss 3.0435696\n",
      "Loss 3.0435498\n",
      "Loss 3.0435297\n",
      "Loss 3.043505\n",
      "Loss 3.0434654\n",
      "Loss 3.0434391\n",
      "Loss 3.0434132\n",
      "Loss 3.0433881\n",
      "Loss 3.0433676\n",
      "Loss 3.0433471\n",
      "Loss 3.0433233\n",
      "Loss 3.0433025\n",
      "Loss 3.0432856\n",
      "Loss 3.043266\n",
      "Loss 3.0432115\n",
      "Loss 3.0431933\n",
      "Loss 3.043165\n",
      "Loss 3.0431123\n",
      "Loss 3.0430894\n",
      "Loss 3.043078\n"
     ]
    }
   ],
   "source": [
    "println(\"Loss $(loss(Xoh,Yoh))\")\n",
    "epochs=200\n",
    "for epoch in 1:epochs\n",
    "    Flux.train!(loss,params(model),data,opt)\n",
    "    println(\"Loss $(loss(Xoh,Yoh))\")\n",
    "\n",
    "end\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"ana.\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out = []\n",
    "context = ones(Int64,block_size)\n",
    "while true\n",
    "    Xoh = reshape(onehotbatch(context',1:vocab_size),block_size*vocab_size,:)\n",
    "    Yoh = model(Xoh)\n",
    "    ix = wsample(1:27,vec(Yoh))\n",
    "    push!(out,itos[ix])\n",
    "    context = vcat(context[2:end],[ix])\n",
    "    if ix == 1 break end\n",
    "end\n",
    "join(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "size(Yoh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.3",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
