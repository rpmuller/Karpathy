{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux, StatsBase, Random\n",
    "using Flux: onehotbatch, onecold, logitcrossentropy, throttle, params\n",
    "using Flux.Data: DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033-element Vector{SubString{String}}:\n",
       " \"lynden\"\n",
       " \"laysha\"\n",
       " \"arina\"\n",
       " \"marguerite\"\n",
       " \"wilbert\"\n",
       " \"haydn\"\n",
       " \"arhaan\"\n",
       " \"jiliana\"\n",
       " \"miyani\"\n",
       " \"derin\"\n",
       " ⋮\n",
       " \"termaine\"\n",
       " \"honesti\"\n",
       " \"haru\"\n",
       " \"bryli\"\n",
       " \"audrie\"\n",
       " \"tavaris\"\n",
       " \"tylasia\"\n",
       " \"sebastiano\"\n",
       " \"mattison\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "words = split(read(\"names.txt\",String),\"\\n\")\n",
    "words[1:10]\n",
    "shuffle!(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Int64, Char} with 27 entries:\n",
       "  5  => 'd'\n",
       "  16 => 'o'\n",
       "  20 => 's'\n",
       "  12 => 'k'\n",
       "  24 => 'w'\n",
       "  8  => 'g'\n",
       "  17 => 'p'\n",
       "  1  => '.'\n",
       "  19 => 'r'\n",
       "  22 => 'u'\n",
       "  23 => 'v'\n",
       "  6  => 'e'\n",
       "  11 => 'j'\n",
       "  9  => 'h'\n",
       "  14 => 'm'\n",
       "  3  => 'b'\n",
       "  7  => 'f'\n",
       "  25 => 'x'\n",
       "  4  => 'c'\n",
       "  ⋮  => ⋮"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create character embeddings. We're going to do this a little\n",
    "# differently, so that we can have the same embeddings AK uses.\n",
    "# I.e. the index of \".\" is 0\n",
    "chars = \".abcdefghijklmnopqrstuvwxyz\"\n",
    "stoi = Dict( s => i for (i,s) in enumerate(chars))\n",
    "itos = Dict( i => s for (i,s) in enumerate(chars))\n",
    "vocab_size = length(chars)\n",
    "itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((228146, 3), (228146,))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compile dataset for neural net:\n",
    "block_size = 3 # context length: how many chars to we use to predict next one?\n",
    "Xi,Y = [],[]\n",
    "\n",
    "for w in words\n",
    "    #println(w)\n",
    "    context = ones(Int64,block_size)\n",
    "    for ch in string(w,\".\")\n",
    "        ix = stoi[ch]\n",
    "        push!(Xi,context)\n",
    "        push!(Y,ix)\n",
    "        #println(join(itos[i] for i in context),\" ---> \", itos[ix])\n",
    "        context = vcat(context[2:end],[ix])\n",
    "    end\n",
    "end\n",
    "\n",
    "\n",
    "# Make into a multidimensional array\n",
    "nrows,ncols = length(Xi),length(Xi[1])\n",
    "X = zeros(Int64,nrows,ncols)\n",
    "for i in 1:nrows\n",
    "    X[i,:] = Xi[i]\n",
    "end\n",
    "\n",
    "ntrial = nrows\n",
    "\n",
    "size(X), size(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28829:32033"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# break the code into training, development, and testing sets\n",
    "nw = length(words)\n",
    "n1 = 8*nw÷10\n",
    "n2 = 9*nw÷10\n",
    "\n",
    "# Ranges are\n",
    "train = 1:n1\n",
    "dev = n1:n2\n",
    "test = n2:nw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "801-element DataLoader(::Tuple{Base.ReshapedArray{Bool, 2, OneHotArrays.OneHotArray{UInt32, 2, 3, Matrix{UInt32}}, Tuple{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64}, Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64}}}, OneHotArrays.OneHotMatrix{UInt32, Vector{UInt32}}}, batchsize=32)\n",
       "  with first element:\n",
       "  (81×32 Matrix{Bool}, 27×32 OneHotMatrix(::Vector{UInt32}) with eltype Bool,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Xoh = reshape(onehotbatch(X[train,:]',1:27),81,:)\n",
    "Yoh = onehotbatch(Y[train],1:27)\n",
    "\n",
    "# If you don't want to use a smaller batchsize, you can just use an array\n",
    "# for data:\n",
    "#data = [(Xoh,Yoh)]\n",
    "data = DataLoader((Xoh,Yoh), batchsize=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(\n",
       "  Dense(81 => 200, tanh),               \u001b[90m# 16_400 parameters\u001b[39m\n",
       "  Dense(200 => 27),                     \u001b[90m# 5_427 parameters\u001b[39m\n",
       "  NNlib.softmax,\n",
       ") \u001b[90m                  # Total: 4 arrays, \u001b[39m21_827 parameters, 85.512 KiB."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss(X,Y) = logitcrossentropy(model(X),Y)\n",
    "\n",
    "n_hidden = 200\n",
    "\n",
    "model = Chain(\n",
    "    Dense(block_size*vocab_size => n_hidden, tanh),\n",
    "    Dense(n_hidden => vocab_size),\n",
    "    softmax\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam(0.0003, (0.9, 0.999), 1.0e-8, IdDict{Any, Any}())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rate = 3e-4\n",
    "opt = Adam(rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 3.2956135\n",
      "Loss 3.1282215\n",
      "Loss 3.106868\n",
      "Loss 3.096329\n",
      "Loss 3.0913324\n",
      "Loss 3.0850065\n",
      "Loss 3.0792758\n",
      "Loss 3.0759058\n",
      "Loss 3.0731313\n",
      "Loss 3.0706923\n",
      "Loss 3.0687437\n",
      "Loss 3.067095\n",
      "Loss 3.0656605\n",
      "Loss 3.0642598\n",
      "Loss 3.063037\n",
      "Loss 3.0620217\n",
      "Loss 3.0610952\n",
      "Loss 3.0602465\n",
      "Loss 3.059474\n",
      "Loss 3.0587769\n",
      "Loss 3.0581422\n",
      "Loss 3.0575576\n",
      "Loss 3.0570166\n",
      "Loss 3.056521\n",
      "Loss 3.056061\n",
      "Loss 3.0556285\n",
      "Loss 3.055218\n",
      "Loss 3.0548246\n",
      "Loss 3.0544417\n",
      "Loss 3.0540574\n",
      "Loss 3.0537083\n",
      "Loss 3.053391\n",
      "Loss 3.053094\n",
      "Loss 3.0528162\n",
      "Loss 3.0525553\n",
      "Loss 3.0523062\n",
      "Loss 3.0520637\n",
      "Loss 3.0518239\n",
      "Loss 3.0515828\n",
      "Loss 3.0513391\n",
      "Loss 3.0510952\n",
      "Loss 3.0508602\n",
      "Loss 3.0506365\n",
      "Loss 3.0504265\n",
      "Loss 3.05023\n",
      "Loss 3.0500255\n",
      "Loss 3.0496838\n",
      "Loss 3.049415\n",
      "Loss 3.0492072\n",
      "Loss 3.0490181\n",
      "Loss 3.0488\n",
      "Loss 3.048576\n",
      "Loss 3.0484085\n",
      "Loss 3.0482569\n",
      "Loss 3.0481145\n",
      "Loss 3.0479786\n",
      "Loss 3.0478482\n",
      "Loss 3.0477204\n",
      "Loss 3.0475938\n",
      "Loss 3.0474637\n",
      "Loss 3.0473228\n",
      "Loss 3.0471864\n",
      "Loss 3.047062\n",
      "Loss 3.0469406\n",
      "Loss 3.0468137\n",
      "Loss 3.046692\n",
      "Loss 3.0465796\n",
      "Loss 3.0464728\n",
      "Loss 3.0463705\n",
      "Loss 3.0462716\n",
      "Loss 3.046176\n",
      "Loss 3.046083\n",
      "Loss 3.0459933\n",
      "Loss 3.0459056\n",
      "Loss 3.0458198\n",
      "Loss 3.0457354\n",
      "Loss 3.045654\n",
      "Loss 3.0455763\n",
      "Loss 3.045503\n",
      "Loss 3.045433\n",
      "Loss 3.045365\n",
      "Loss 3.0452986\n",
      "Loss 3.0452335\n",
      "Loss 3.0451689\n",
      "Loss 3.0451043\n",
      "Loss 3.0450392\n",
      "Loss 3.044973\n",
      "Loss 3.0449061\n",
      "Loss 3.0448403\n",
      "Loss 3.0447733\n",
      "Loss 3.0446982\n",
      "Loss 3.044602\n",
      "Loss 3.0445342\n",
      "Loss 3.044477\n",
      "Loss 3.0444226\n",
      "Loss 3.044369\n",
      "Loss 3.044316\n",
      "Loss 3.0442636\n",
      "Loss 3.044212\n",
      "Loss 3.044161\n",
      "Loss 3.0441117\n",
      "Loss 3.0440633\n",
      "Loss 3.044016\n",
      "Loss 3.0439696\n",
      "Loss 3.0439246\n",
      "Loss 3.04388\n",
      "Loss 3.0438364\n",
      "Loss 3.0437934\n",
      "Loss 3.0437512\n",
      "Loss 3.0437093\n",
      "Loss 3.0436685\n",
      "Loss 3.0436275\n",
      "Loss 3.0435877\n",
      "Loss 3.0435476\n",
      "Loss 3.043509\n",
      "Loss 3.0434709\n",
      "Loss 3.0434337\n",
      "Loss 3.0433962\n",
      "Loss 3.0433595\n",
      "Loss 3.043322\n",
      "Loss 3.043285\n",
      "Loss 3.0432475\n",
      "Loss 3.0432107\n",
      "Loss 3.0431747\n",
      "Loss 3.0431414\n",
      "Loss 3.0431075\n",
      "Loss 3.0430756\n",
      "Loss 3.0430446\n",
      "Loss 3.0430157\n",
      "Loss 3.0429866\n",
      "Loss 3.0429564\n",
      "Loss 3.0429232\n",
      "Loss 3.04289\n",
      "Loss 3.0428586\n",
      "Loss 3.0428307\n",
      "Loss 3.0428038\n",
      "Loss 3.0427783\n",
      "Loss 3.042752\n",
      "Loss 3.0427263\n",
      "Loss 3.0427015\n",
      "Loss 3.0426774\n",
      "Loss 3.0426536\n",
      "Loss 3.0426283\n",
      "Loss 3.0425992\n",
      "Loss 3.042562\n",
      "Loss 3.042526\n",
      "Loss 3.0424922\n",
      "Loss 3.0424597\n",
      "Loss 3.0424263\n",
      "Loss 3.0423827\n",
      "Loss 3.0423226\n",
      "Loss 3.042259\n",
      "Loss 3.042215\n",
      "Loss 3.0421789\n",
      "Loss 3.0421438\n",
      "Loss 3.0421135\n",
      "Loss 3.0420892\n",
      "Loss 3.042067\n",
      "Loss 3.042041\n",
      "Loss 3.0420134\n",
      "Loss 3.041991\n",
      "Loss 3.0419688\n",
      "Loss 3.0419447\n",
      "Loss 3.041921\n",
      "Loss 3.0418997\n",
      "Loss 3.0418804\n",
      "Loss 3.041861\n",
      "Loss 3.041841\n",
      "Loss 3.0418198\n",
      "Loss 3.0417984\n",
      "Loss 3.0417755\n",
      "Loss 3.04175\n",
      "Loss 3.0417216\n",
      "Loss 3.0417001\n",
      "Loss 3.0416837\n",
      "Loss 3.0416694\n",
      "Loss 3.0416546\n",
      "Loss 3.0416405\n",
      "Loss 3.0416265\n",
      "Loss 3.0416136\n",
      "Loss 3.0416014\n",
      "Loss 3.0415907\n",
      "Loss 3.0415795\n",
      "Loss 3.0415678\n",
      "Loss 3.0415545\n",
      "Loss 3.0415413\n",
      "Loss 3.0415292\n",
      "Loss 3.0415184\n",
      "Loss 3.0415082\n",
      "Loss 3.0414994\n",
      "Loss 3.041491\n",
      "Loss 3.0414836\n",
      "Loss 3.0414765\n",
      "Loss 3.0414686\n",
      "Loss 3.0414605\n",
      "Loss 3.0414536\n",
      "Loss 3.0414472\n",
      "Loss 3.0414398\n",
      "Loss 3.0414326\n",
      "Loss 3.0414243\n",
      "Loss 3.0414147\n"
     ]
    }
   ],
   "source": [
    "println(\"Loss $(loss(Xoh,Yoh))\")\n",
    "epochs=200\n",
    "for epoch in 1:epochs\n",
    "    Flux.train!(loss,params(model),data,opt)\n",
    "    println(\"Loss $(loss(Xoh,Yoh))\")\n",
    "\n",
    "end\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"alee.\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out = []\n",
    "context = ones(Int64,block_size)\n",
    "while true\n",
    "    Xoh = reshape(onehotbatch(context',1:vocab_size),block_size*vocab_size,:)\n",
    "    Yoh = model(Xoh)\n",
    "    ix = wsample(1:27,vec(Yoh))\n",
    "    push!(out,itos[ix])\n",
    "    context = vcat(context[2:end],[ix])\n",
    "    if ix == 1 break end\n",
    "end\n",
    "join(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "size(Yoh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.2",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
