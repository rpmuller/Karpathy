{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux, StatsBase, Random\n",
    "using Flux: onehotbatch, onecold, logitcrossentropy, throttle, params\n",
    "using Flux.Data: DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033-element Vector{SubString{String}}:\n",
       " \"nihaan\"\n",
       " \"khizar\"\n",
       " \"dajuan\"\n",
       " \"allianna\"\n",
       " \"talula\"\n",
       " \"panth\"\n",
       " \"ziqi\"\n",
       " \"malory\"\n",
       " \"kathaleia\"\n",
       " \"benicio\"\n",
       " ⋮\n",
       " \"jeffrey\"\n",
       " \"zofia\"\n",
       " \"mahelet\"\n",
       " \"journii\"\n",
       " \"sela\"\n",
       " \"emunah\"\n",
       " \"locklen\"\n",
       " \"yahsir\"\n",
       " \"laiyla\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "words = split(read(\"names.txt\",String),\"\\n\")\n",
    "words[1:10]\n",
    "shuffle!(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Int64, Char} with 27 entries:\n",
       "  5  => 'd'\n",
       "  16 => 'o'\n",
       "  20 => 's'\n",
       "  12 => 'k'\n",
       "  24 => 'w'\n",
       "  8  => 'g'\n",
       "  17 => 'p'\n",
       "  1  => '.'\n",
       "  19 => 'r'\n",
       "  22 => 'u'\n",
       "  23 => 'v'\n",
       "  6  => 'e'\n",
       "  11 => 'j'\n",
       "  9  => 'h'\n",
       "  14 => 'm'\n",
       "  3  => 'b'\n",
       "  7  => 'f'\n",
       "  25 => 'x'\n",
       "  4  => 'c'\n",
       "  ⋮  => ⋮"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create character embeddings. We're going to do this a little\n",
    "# differently, so that we can have the same embeddings AK uses.\n",
    "# I.e. the index of \".\" is 0\n",
    "chars = \".abcdefghijklmnopqrstuvwxyz\"\n",
    "stoi = Dict( s => i for (i,s) in enumerate(chars))\n",
    "itos = Dict( i => s for (i,s) in enumerate(chars))\n",
    "vocab_size = length(chars)\n",
    "itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((228146, 3), (228146,))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compile dataset for neural net:\n",
    "block_size = 3 # context length: how many chars to we use to predict next one?\n",
    "Xi,Y = [],[]\n",
    "\n",
    "for w in words\n",
    "    #println(w)\n",
    "    context = ones(Int64,block_size)\n",
    "    for ch in string(w,\".\")\n",
    "        ix = stoi[ch]\n",
    "        push!(Xi,context)\n",
    "        push!(Y,ix)\n",
    "        #println(join(itos[i] for i in context),\" ---> \", itos[ix])\n",
    "        context = vcat(context[2:end],[ix])\n",
    "    end\n",
    "end\n",
    "\n",
    "\n",
    "# Make into a multidimensional array\n",
    "nrows,ncols = length(Xi),length(Xi[1])\n",
    "X = zeros(Int64,nrows,ncols)\n",
    "for i in 1:nrows\n",
    "    X[i,:] = Xi[i]\n",
    "end\n",
    "\n",
    "ntrial = nrows\n",
    "\n",
    "size(X), size(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "205331:228146"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# break the code into training, development, and testing sets\n",
    "n1 = 8*nrows÷10\n",
    "n2 = 9*nrows÷10\n",
    "\n",
    "# Ranges are\n",
    "train = 1:n1\n",
    "dev = n1:n2\n",
    "test = n2:nrows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5704-element DataLoader(::Tuple{Base.ReshapedArray{Bool, 2, OneHotArrays.OneHotArray{UInt32, 2, 3, Matrix{UInt32}}, Tuple{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64}, Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64}}}, OneHotArrays.OneHotMatrix{UInt32, Vector{UInt32}}}, batchsize=32)\n",
       "  with first element:\n",
       "  (81×32 Matrix{Bool}, 27×32 OneHotMatrix(::Vector{UInt32}) with eltype Bool,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Xoh = reshape(onehotbatch(X[train,:]',1:27),81,:)\n",
    "Yoh = onehotbatch(Y[train],1:27)\n",
    "\n",
    "# If you don't want to use a smaller batchsize, you can just use an array\n",
    "# for data:\n",
    "#data = [(Xoh,Yoh)]\n",
    "data = DataLoader((Xoh,Yoh), batchsize=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(\n",
       "  Dense(81 => 200, tanh),               \u001b[90m# 16_400 parameters\u001b[39m\n",
       "  Dense(200 => 27),                     \u001b[90m# 5_427 parameters\u001b[39m\n",
       "  NNlib.softmax,\n",
       ") \u001b[90m                  # Total: 4 arrays, \u001b[39m21_827 parameters, 85.512 KiB."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss(X,Y) = logitcrossentropy(model(X),Y)\n",
    "\n",
    "n_hidden = 200\n",
    "\n",
    "model = Chain(\n",
    "    Dense(block_size*vocab_size => n_hidden, tanh),\n",
    "    Dense(n_hidden => vocab_size),\n",
    "    softmax\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam(0.0003, (0.9, 0.999), 1.0e-8, IdDict{Any, Any}())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rate = 3e-4\n",
    "opt = Adam(rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 2.3575342\n",
      "Loss 2.3575342\n",
      "Loss 2.3575342\n",
      "Loss 2.3575342\n",
      "Loss 2.3575342\n",
      "Loss 2.3575342\n",
      "Loss 2.3575342\n",
      "Loss 2.3575342\n",
      "Loss 2.3575342\n",
      "Loss 2.3575342\n",
      "Loss 2.3575342\n",
      "Loss 2.3575342\n",
      "Loss 2.3575342\n",
      "Loss 2.3575342\n",
      "Loss 2.3575342\n",
      "Loss 2.3575342\n",
      "Loss 2.3575342\n",
      "Loss 2.3575342\n",
      "Loss 2.3575342\n",
      "Loss 2.3575342\n",
      "Loss 2.3575342\n"
     ]
    }
   ],
   "source": [
    "println(\"Loss $(loss(Xoh,Yoh))\")\n",
    "epochs=20\n",
    "for epoch in 1:epochs\n",
    "    Flux.train!(loss,params(model),data,opt)\n",
    "    println(\"Loss $(loss(Xoh,Yoh))\")\n",
    "end\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context = [1, 1, 2]\n",
      "context = [1, 2, 19]\n",
      "context = [2, 19, 10]\n",
      "context = [19, 10, 2]\n",
      "context = [10, 2, 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"aria.\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out = []\n",
    "context = ones(Int64,block_size)\n",
    "while true\n",
    "    Xoh = reshape(onehotbatch(context',1:vocab_size),block_size*vocab_size,:)\n",
    "    Yoh = model(Xoh)\n",
    "    ix = wsample(1:27,vec(Yoh))\n",
    "    push!(out,itos[ix])\n",
    "    context = vcat(context[2:end],[ix])\n",
    "    @show context\n",
    "    if ix == 1 break end\n",
    "end\n",
    "join(out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging MLP\n",
    "Okay, we're getting some bad results from the code. For one thing, everything starts with \"a\". I'm also not getting much randomness for the successive guesses.\n",
    "\n",
    "I'm going to make some tools to see whether I can figure out what's going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "letterprobs (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function next_letter_probs(input)\n",
    "    # Usage: next_letter_probs(\"..a\")\n",
    "    # output a dict something like \"n\" => 0.8, \"r\" => 0.1, ...\n",
    "\n",
    "    # Force input to be 3 chars:\n",
    "    context = [stoi[input[i]] for i in 1:block_size] \n",
    "    X = reshape(onehotbatch(context',1:vocab_size),block_size*vocab_size,:)\n",
    "    Y = vec(model(X))\n",
    "    return letterprobs(Y)\n",
    "    #out = [(round(p,digits=3),itos[i]) for (i,p) in enumerate(Y) if p>1e-4 ]\n",
    "    #return reverse(sort(out))\n",
    "end\n",
    "\n",
    "letterprobs(Y) = reverse(sort([(round(p,digits=3),itos[i]) for (i,p) in enumerate(Y) if p>1e-4 ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Vector{Tuple{Float32, Char}}:\n",
       " (1.0, 'a')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "next_letter_probs(\"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Vector{Tuple{Float32, Char}}:\n",
       " (0.838, 'r')\n",
       " (0.161, 'l')\n",
       " (0.0, 'a')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "next_letter_probs(\"..a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context = [1, 1, 1]\n",
      "letterprobs(Yi) = Tuple{Float32, Char}[(1.0, 'a')]\n",
      "itos[Y[i]] = 'n'\n",
      "context = [1, 1, 15]\n",
      "letterprobs(Yi) = Tuple{Float32, Char}[(1.0, 'a')]\n",
      "itos[Y[i]] = 'i'\n",
      "context = [1, 15, 10]\n",
      "letterprobs(Yi) = Tuple{Float32, Char}[(0.999, 'a'), (0.001, 'e')]\n",
      "itos[Y[i]] = 'h'\n",
      "context = [15, 10, 9]\n",
      "letterprobs(Yi) = Tuple{Float32, Char}[(1.0, 'a')]\n",
      "itos[Y[i]] = 'a'\n",
      "context = [10, 9, 2]\n",
      "letterprobs(Yi) = Tuple{Float32, Char}[(0.996, 'n'), (0.004, '.')]\n",
      "itos[Y[i]] = 'a'\n",
      "context = [9, 2, 2]\n",
      "letterprobs(Yi) = Tuple{Float32, Char}[(0.999, '.'), (0.001, 'l'), (0.0, 'r')]\n",
      "itos[Y[i]] = 'n'\n",
      "context = [2, 2, 15]\n",
      "letterprobs(Yi) = Tuple{Float32, Char}[(0.999, '.'), (0.001, 'i')]\n",
      "itos[Y[i]] = '.'\n",
      "context = [1, 1, 1]\n",
      "letterprobs(Yi) = Tuple{Float32, Char}[(1.0, 'a')]\n",
      "itos[Y[i]] = 'k'\n",
      "context = [1, 1, 12]\n",
      "letterprobs(Yi) = Tuple{Float32, Char}[(1.0, 'a')]\n",
      "itos[Y[i]] = 'h'\n",
      "context = [1, 12, 9]\n",
      "letterprobs(Yi) = Tuple{Float32, Char}[(1.0, 'a')]\n",
      "itos[Y[i]] = 'i'\n",
      "context = [12, 9, 10]\n",
      "letterprobs(Yi) = Tuple{Float32, Char}[(0.996, 'l'), (0.004, 'a')]\n",
      "itos[Y[i]] = 'z'\n",
      "context = [9, 10, 27]\n",
      "letterprobs(Yi) = Tuple{Float32, Char}[(1.0, 'a')]\n",
      "itos[Y[i]] = 'a'\n",
      "context = [10, 27, 2]\n",
      "letterprobs(Yi) = Tuple{Float32, Char}[(1.0, '.')]\n",
      "itos[Y[i]] = 'r'\n",
      "context = [27, 2, 19]\n",
      "letterprobs(Yi) = Tuple{Float32, Char}[(1.0, 'i')]\n",
      "itos[Y[i]] = '.'\n",
      "context = [1, 1, 1]\n",
      "letterprobs(Yi) = Tuple{Float32, Char}[(1.0, 'a')]\n",
      "itos[Y[i]] = 'd'\n",
      "context = [1, 1, 5]\n",
      "letterprobs(Yi) = Tuple{Float32, Char}[(1.0, 'a')]\n",
      "itos[Y[i]] = 'a'\n",
      "context = [1, 5, 2]\n",
      "letterprobs(Yi) = Tuple{Float32, Char}[(0.996, 'r'), (0.004, 'n')]\n",
      "itos[Y[i]] = 'j'\n",
      "context = [5, 2, 11]\n",
      "letterprobs(Yi) = Tuple{Float32, Char}[(1.0, 'a')]\n",
      "itos[Y[i]] = 'u'\n",
      "context = [2, 11, 22]\n",
      "letterprobs(Yi) = Tuple{Float32, Char}[(0.886, 'n'), (0.057, 'l'), (0.054, 'r'), (0.003, 's'), (0.0, 'u')]\n",
      "itos[Y[i]] = 'a'\n",
      "context = [11, 22, 2]\n",
      "letterprobs(Yi) = Tuple{Float32, Char}[(0.995, 'n'), (0.005, 'r'), (0.0, '.')]\n",
      "itos[Y[i]] = 'n'\n"
     ]
    }
   ],
   "source": [
    "for i in 1:20\n",
    "    context = X[i,:]\n",
    "    Xi = reshape(onehotbatch(context',1:vocab_size),block_size*vocab_size,:)\n",
    "    Yi = vec(model(Xi))\n",
    "    @show context\n",
    "    @show letterprobs(Yi)\n",
    "    @show itos[Y[i]]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.3",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
